{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bffa521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import pipeline, linear_model, model_selection, metrics, multioutput, svm, preprocessing\n",
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b208f",
   "metadata": {},
   "source": [
    "# Create vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a056f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change for subtitle dataset\n",
    "X_train = pd.read_csv('X_train_sum.csv')\n",
    "y_train = pd.read_csv('y_train_sum.csv')\n",
    "X_test = pd.read_csv('X_test_sum.csv')\n",
    "y_test = pd.read_csv('y_test_sum.csv')\n",
    "target_names = y_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3f17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train and evaluate model with given features, and save predictions.\"\"\"\n",
    "def evalmodel(X_train, X_test, y_train, y_test, target_names, output_file):\n",
    "    clf = LogisticRegression(penalty='l2', class_weight='balanced', random_state=0, solver='liblinear', max_iter=1000)\n",
    "    clf_tuned = TunedThresholdClassifierCV(clf, cv=10, n_jobs=-1)\n",
    "    model = multioutput.MultiOutputClassifier(clf_tuned)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Save predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame(y_pred, columns=target_names)\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Generate classification report and accuracy\n",
    "    scores = pd.DataFrame(metrics.classification_report(y_test, y_pred, target_names=target_names, zero_division=0, output_dict=True)).T\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model, scores, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6316aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit(X_test, vectorizer):\n",
    "    X_test = vectorizer.transform(X_test['summary'])\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5041f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_train, y_train, X_test, y_test, n1, n2, max_words, target_names, output_file):\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (n1,n2), max_features = max_words, norm = 'l2', sublinear_tf= True)\n",
    "    vec = vectorizer.fit_transform(X_train['summary'])\n",
    "    X_t = test_fit(X_test, vectorizer)\n",
    "    model, scores, accuracy = evalmodel(vec, X_t, y_train, y_test, target_names, output_file)\n",
    "    return model, scores, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544226d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiOutputClassifier(estimator=TunedThresholdClassifierCV(cv=10,\n",
       "                                                            estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                                                         max_iter=1000,\n",
       "                                                                                         random_state=0,\n",
       "                                                                                         solver='liblinear'),\n",
       "                                                            n_jobs=-1)),\n",
       "                           precision    recall  f1-score  support\n",
       " husband and wife           0.476190  0.769231  0.588235     26.0\n",
       " infatuation                0.407407  0.611111  0.488889     18.0\n",
       " friendship                 0.193548  0.900000  0.318584     20.0\n",
       " romantic love              0.147541  0.642857  0.240000     14.0\n",
       " the desire for vengeance   0.242424  0.500000  0.326531     16.0\n",
       " humanoid robot             0.600000  0.937500  0.731707     16.0\n",
       " father and son             0.363636  0.923077  0.521739     13.0\n",
       " human vs. captivity        0.241379  0.636364  0.350000     11.0\n",
       " time travel                0.391304  0.750000  0.514286     12.0\n",
       " greed for riches           0.292683  0.800000  0.428571     15.0\n",
       " micro avg                  0.297297  0.751553  0.426056    161.0\n",
       " macro avg                  0.335611  0.747014  0.450854    161.0\n",
       " weighted avg               0.345329  0.751553  0.459567    161.0\n",
       " samples avg                0.329845  0.764858  0.437062    161.0,\n",
       " 0.03875968992248062)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust n in n-grams, max_words and output_file\n",
    "prediction(X_train, y_train, X_test, y_test, 1, 2, 5000, target_names,\"results/summary/10f/sum_logreg_bigram_5000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb87224",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6096dfef-5343-49db-9628-a85858591b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalmodel2(X_train, X_test, y_train, y_test, target_names, output_file):\n",
    "    \"\"\"Train and evaluate model with given features, and save predictions.\"\"\"\n",
    "    clf = svm.LinearSVC(class_weight='balanced', random_state=0)\n",
    "    clf_tuned = TunedThresholdClassifierCV(clf, cv=10, n_jobs=-1)\n",
    "    model = multioutput.MultiOutputClassifier(clf_tuned)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Save predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame(y_pred, columns=target_names)\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Generate classification report and accuracy\n",
    "    scores = pd.DataFrame(metrics.classification_report(y_test, y_pred, target_names=target_names, zero_division=0, output_dict=True)).T\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model, scores, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f41002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction2(X_train, y_train, X_test, y_test, n1, n2, max_words, target_names, output_file):\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (n1,n2), max_features = max_words, norm = 'l2', sublinear_tf= True)\n",
    "    vec = vectorizer.fit_transform(X_train['summary'])\n",
    "    X_t = test_fit(X_test, vectorizer)\n",
    "    model, scores, accuracy = evalmodel2(vec, X_t, y_train, y_test, target_names, output_file)\n",
    "    return model, scores, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cf2e96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiOutputClassifier(estimator=TunedThresholdClassifierCV(cv=10,\n",
       "                                                            estimator=LinearSVC(class_weight='balanced',\n",
       "                                                                                random_state=0),\n",
       "                                                            n_jobs=-1)),\n",
       "                           precision    recall  f1-score  support\n",
       " husband and wife           0.512821  0.769231  0.615385     26.0\n",
       " infatuation                0.375000  0.666667  0.480000     18.0\n",
       " friendship                 0.218391  0.950000  0.355140     20.0\n",
       " romantic love              0.180000  0.642857  0.281250     14.0\n",
       " the desire for vengeance   0.294118  0.625000  0.400000     16.0\n",
       " humanoid robot             0.576923  0.937500  0.714286     16.0\n",
       " father and son             0.400000  0.923077  0.558140     13.0\n",
       " human vs. captivity        0.320000  0.727273  0.444444     11.0\n",
       " time travel                0.818182  0.750000  0.782609     12.0\n",
       " greed for riches           0.333333  0.800000  0.470588     15.0\n",
       " micro avg                  0.340541  0.782609  0.474576    161.0\n",
       " macro avg                  0.402877  0.779160  0.510184    161.0\n",
       " weighted avg               0.400286  0.782609  0.509961    161.0\n",
       " samples avg                0.372481  0.803618  0.482577    161.0,\n",
       " 0.05426356589147287)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust n in n-grams, max_words and output_file\n",
    "prediction2(X_train, y_train, X_test, y_test, 1, 2, 10000, target_names, \"results/summary/10f/sum_svm_bigram_10000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f91c1",
   "metadata": {},
   "source": [
    "# Fast text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ae8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing summaries as proper input for fast text\n",
    "train_texts = X_train['summary'].str.replace('\\n', ' ', regex=False).str.strip().tolist()\n",
    "test_texts = X_test['summary'].str.replace('\\n', ' ', regex=False).str.strip().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ec0085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = list(X_train['theme'])\n",
    "test_labels = list(X_test['theme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2064022",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aa554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                          precision    recall  f1-score  support\n",
       " husband and wife           0.432432  0.615385  0.507937     26.0\n",
       " infatuation                0.232558  0.555556  0.327869     18.0\n",
       " friendship                 0.180000  0.450000  0.257143     20.0\n",
       " romantic love              0.137255  0.500000  0.215385     14.0\n",
       " the desire for vengeance   0.140351  0.500000  0.219178     16.0\n",
       " humanoid robot             0.451613  0.875000  0.595745     16.0\n",
       " father and son             0.222222  0.615385  0.326531     13.0\n",
       " human vs. captivity        0.173913  0.727273  0.280702     11.0\n",
       " time travel                0.189189  0.583333  0.285714     12.0\n",
       " greed for riches           0.187500  0.600000  0.285714     15.0\n",
       " micro avg                  0.220183  0.596273  0.321608    161.0\n",
       " macro avg                  0.234703  0.602193  0.330192    161.0\n",
       " weighted avg               0.250354  0.596273  0.343801    161.0\n",
       " samples avg                0.239664  0.602067  0.318691    161.0,\n",
       " 0.031007751937984496)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained FastText model\n",
    "# make sure to download & change file path before running\n",
    "model_ft = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Generate embeddings for each text in train and test data\n",
    "# note whole summary is processed as a \"sentence\"\n",
    "train_embeddings = np.array([model_ft.get_sentence_vector(text) for text in train_texts])\n",
    "test_embeddings = np.array([model_ft.get_sentence_vector(text) for text in test_texts])\n",
    "model, scores, accuracy = evalmodel(train_embeddings, test_embeddings, y_train, y_test, target_names,\"results/sum_fast_logreg.csv\")\n",
    "\n",
    "scores, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a1d10",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656cf299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                          precision    recall  f1-score  support\n",
       " husband and wife           0.404762  0.653846  0.500000     26.0\n",
       " infatuation                0.235294  0.444444  0.307692     18.0\n",
       " friendship                 0.147826  0.850000  0.251852     20.0\n",
       " romantic love              0.126984  0.571429  0.207792     14.0\n",
       " the desire for vengeance   0.145455  0.500000  0.225352     16.0\n",
       " humanoid robot             0.500000  0.875000  0.636364     16.0\n",
       " father and son             0.258065  0.615385  0.363636     13.0\n",
       " human vs. captivity        0.177778  0.727273  0.285714     11.0\n",
       " time travel                0.200000  0.416667  0.270270     12.0\n",
       " greed for riches           0.217391  0.666667  0.327869     15.0\n",
       " micro avg                  0.212810  0.639752  0.319380    161.0\n",
       " macro avg                  0.241355  0.632071  0.337654    161.0\n",
       " weighted avg               0.253366  0.639752  0.349711    161.0\n",
       " samples avg                0.227593  0.651163  0.317682    161.0,\n",
       " 0.023255813953488372)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained FastText model\n",
    "model_ft = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Generate embeddings for each text in train and test data\n",
    "# note whole summary is processed as a \"sentence\"\n",
    "train_embeddings = np.array([model_ft.get_sentence_vector(text) for text in train_texts])\n",
    "test_embeddings = np.array([model_ft.get_sentence_vector(text) for text in test_texts])\n",
    "\n",
    "\n",
    "model, scores, accuracy = evalmodel2(train_embeddings, test_embeddings, y_train, y_test, target_names,\"results/sum_fast_svm.csv\")\n",
    "\n",
    "scores, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
